#http://archive.ics.uci.edu/ml/machine-learning-databases/spambase/

spam <- read.table(file= "http://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data",
              sep = ",")
dim(spam)
set.seed(123)
flag <- sort(sample(4601,1536, replace = FALSE))
spamtrain <- spam[-flag,]
spamtest <- spam[flag,]
dim(spamtrain)
dim(spamtest)
dim(spamtest[spamtest$V58 ==1,])
y1    <- spamtrain$V58;
y2    <- spamtest$V58;

##CART, using rpart package
library(rpart)

## grow tree
rpart.spam1 <- rpart(V58 ~ .,data=spamtrain, method="class", parms=list(split="gini"))

## another way to grow tree
rpart.spam2 <- rpart(V58 ~ .,data=spamtrain, method="class", parms=list(split="information"))

## Initial Tree T0, we have 6 terminal nodes
print(rpart.spam1)
post(rpart.spam1,filename="")

## Or simplified plot
plot(rpart.spam1,compress=TRUE)
text(rpart.spam1)


## Training & Test Errors for Tree T0
y1hatc <- ifelse(predict(rpart.spam1,spamtrain)[,2] < 0.5, 0, 1)
sum(y1hatc != y1)/length(y1)
#  0.1017945 (training error for T0)
y2hatc <-  predict(rpart.spam1, spamtest[,-58],type="class")
sum(y2hatc != y2)/length(y2)
# 0.1015625 (test error for T0)


## To determine whether the tree T0 is appropriate or if some of 
##    the branches need to be pruned 


printcp(rpart.spam1)
## or 
#print(rpart.spam1$cptable)


## The xerror column is the estimates of cross-validated prediction
##   error for different numbers of splits. 
##   Here the best tree turns out to be T0

opt <- which.min(rpart.spam1$cptable[, "xerror"]); 
cp1 <- rpart.spam1$cptable[opt, "CP"];
rpart.pruned1 <- prune(rpart.spam1,cp=cp1);
## This is same as T0 in this example. Maybe different in other problems

## Try another cp
cp1 <- 0.0262;
rpart.pruned1 <- prune(rpart.spam1,cp=cp1);
y2hatc1 <-  predict(rpart.pruned1, spamtest[,-58],type="class")
sum(y2hatc1 != y2)/length(y2)
## 0.1184896 (test error for the pruned tree, vs 0.1015625 for T0)


## Compare T01 and T1, collapes V57
par(mfrow=c(1,2))
post(rpart.spam1,filename="")
post(rpart.pruned1,filename="")


## Alternatively, we can plot Complexity Parameter table 
##  A hortizontal line is drawn 1 SE above the minimum of curve
##  A good choice of Cp for pruning is often the leftmost value
##  for which the mean lies below the horizontal line
plotcp(rpart.spam1)
cp2 <- 0.03; 
rpart.pruned2 <- prune(rpart.spam1,cp=cp2);

## This leads to the same tree as rpart.pruned1

## Try another tree T2
rpart.pruned3 <- prune(rpart.spam1,cp=0.43)
y2hatc3 <-  predict(rpart.pruned3, spamtest[,-58],type="class")
sum(y2hatc3 != y2)/length(y2)
## 0.2083333 (test error for T2) 